{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Sample Dataset"
      ],
      "metadata": {
        "id": "Qe4sSsoNRXp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To access files stored in your Google Drive from a Google Colab notebook, you need to mount your Google Drive. The following code mounts your Google Drive to the Colab environment, allowing you to read and write files directly from your Drive.\n"
      ],
      "metadata": {
        "id": "bEOPqi5yJUAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YJH9q8De01v",
        "outputId": "1e581bcb-0586-45a2-f3fe-0fc0725e45ed"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code extracts the contents of a ZIP file stored in your Google Drive to a specified directory in the Colab environment. The script first ensures that the destination directory exists and then unzips the file into that directory.\n",
        "\n",
        "- `file_path`: this is the file path that contain your zipped dataset\n",
        "- `destination_path`: this is the file destination to save the unzipped dataset\n"
      ],
      "metadata": {
        "id": "HQX17HY7Jiss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "file_path = '/content/drive/MyDrive/HistopatologyBreastCancerM400X_unhas_makassar.zip'\n",
        "destination_path = '/content/HistopatologyBreastCancerM400X_unhas_makassar.zip'\n",
        "\n",
        "# Create the destination directory if it doesn't exist\n",
        "os.makedirs(destination_path, exist_ok=True)\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(destination_path)\n",
        "\n",
        "print(f\"Unzipped file to {destination_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Yv6jCRce8kS",
        "outputId": "062cc1ec-de0b-41eb-bb24-fbb34ebb3f0a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipped file to /content/HistopatologyBreastCancerM400X_unhas_makassar.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Creating Validation Set"
      ],
      "metadata": {
        "id": "bmH2d01julC7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code defines a function called `count_class` that counts the number of images in two different directories, representing two classes of data (e.g., benign and malignant images).\n",
        "\n",
        "### Inputs:\n",
        "- `path1`: The file path to the directory containing images for the first class (e.g., benign).\n",
        "- `path2`: The file path to the directory containing images for the second class (e.g., malignant).\n",
        "\n",
        "### Functionality:\n",
        "The function calculates the number of files in each directory and prints out the count for each class as well as the total number of images in both directories combined.\n",
        "\n",
        "The function is then called with specific paths (`path_1` and `path_2`), which point to directories within the unzipped dataset containing images of benign and malignant tumors, respectively.\n"
      ],
      "metadata": {
        "id": "s0pVZmuxKGFV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_class(path1, path2):\n",
        "  training_data_negative = path1\n",
        "  training_data_positive = path2\n",
        "  len_negative = len(os.listdir(training_data_negative))\n",
        "  len_positive = len(os.listdir(training_data_positive))\n",
        "  print(f'Class 1: {len_negative}')\n",
        "  print(f'Class 2: {len_positive}')\n",
        "  print(f'Total: {len_negative+len_positive}')\n",
        "\n",
        "path_1 = '/content/HistopatologyBreastCancerM400X_unhas_makassar.zip/HistopatologyBreastCancerM400X/train/benign'\n",
        "path_2 = '/content/HistopatologyBreastCancerM400X_unhas_makassar.zip/HistopatologyBreastCancerM400X/train/malignant'\n",
        "count_class(path_1, path_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbxoxEkNt7mm",
        "outputId": "1dc7af6d-7cf6-42f3-fb9e-fd59314a31fd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 1: 371\n",
            "Class 2: 777\n",
            "Total: 1148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code defines a function called `create_validation_split` that creates a validation dataset by splitting off a portion of the images from the training dataset. The selected validation images are moved to a separate directory.\n",
        "\n",
        "### Inputs:\n",
        "- `train_data_dir`: The directory containing the training data, where each class has its own subdirectory.\n",
        "- `validation_data_dir`: The directory where the validation data will be stored, with the same class subdirectory structure as the training data.\n",
        "- `validation_split`: The proportion of the training data to move to the validation set (default is 20%).\n",
        "- `seed`: A random seed to ensure reproducibility of the split (default is 123).\n",
        "\n",
        "### Functionality:\n",
        "The function:\n",
        "1. Ensures the validation directory exists.\n",
        "2. Iterates through each class subdirectory in the training data directory.\n",
        "3. Splits the images in each class into training and validation sets based on the specified split ratio.\n",
        "4. Moves the selected validation images from the training directory to the corresponding class subdirectory in the validation directory.\n",
        "\n",
        "After running this function, the validation set will be separated from the training set, which is useful for model evaluation.\n"
      ],
      "metadata": {
        "id": "EAgyx_o4LReB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def create_validation_split(train_data_dir, validation_data_dir, validation_split=0.2, seed=123):\n",
        "    # Ensure the validation directory exists\n",
        "    if not os.path.exists(validation_data_dir):\n",
        "        os.makedirs(validation_data_dir)\n",
        "\n",
        "    # Loop through each class directory in the training data\n",
        "    for class_name in os.listdir(train_data_dir):\n",
        "        class_dir = os.path.join(train_data_dir, class_name)\n",
        "        if os.path.isdir(class_dir):\n",
        "            # List all files in the class directory\n",
        "            images = os.listdir(class_dir)\n",
        "            train_images, val_images = train_test_split(images, test_size=validation_split, random_state=seed)\n",
        "\n",
        "            # Create class directory in the validation directory\n",
        "            val_class_dir = os.path.join(validation_data_dir, class_name)\n",
        "            if not os.path.exists(val_class_dir):\n",
        "                os.makedirs(val_class_dir)\n",
        "\n",
        "            # Move the validation images to the validation directory\n",
        "            for img_name in val_images:\n",
        "                src = os.path.join(class_dir, img_name)\n",
        "                dst = os.path.join(val_class_dir, img_name)\n",
        "                shutil.move(src, dst)\n",
        "\n",
        "            print(f\"Moved {len(val_images)} images to {val_class_dir}\")"
      ],
      "metadata": {
        "id": "rSB7zJTQtaTY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = '/content/HistopatologyBreastCancerM400X_unhas_makassar.zip/HistopatologyBreastCancerM400X/train'\n",
        "validation_data = '/content/HistopatologyBreastCancerM400X_unhas_makassar.zip/HistopatologyBreastCancerM400X/validation'\n",
        "create_validation_split(training_data, validation_data, validation_split=0.2, seed=123)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsRV-hxRtdQ4",
        "outputId": "91a7fcba-5352-4585-a78f-1ca23eced9da"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moved 75 images to /content/HistopatologyBreastCancerM400X_unhas_makassar.zip/HistopatologyBreastCancerM400X/validation/benign\n",
            "Moved 156 images to /content/HistopatologyBreastCancerM400X_unhas_makassar.zip/HistopatologyBreastCancerM400X/validation/malignant\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_1 = '/content/HistopatologyBreastCancerM400X_unhas_makassar.zip/HistopatologyBreastCancerM400X/train/benign'\n",
        "path_2 = '/content/HistopatologyBreastCancerM400X_unhas_makassar.zip/HistopatologyBreastCancerM400X/train/malignant'\n",
        "count_class(path_1, path_2)\n",
        "\n",
        "path_1 = '/content/HistopatologyBreastCancerM400X_unhas_makassar.zip/HistopatologyBreastCancerM400X/validation/benign'\n",
        "path_2 = '/content/HistopatologyBreastCancerM400X_unhas_makassar.zip/HistopatologyBreastCancerM400X/validation/malignant'\n",
        "count_class(path_1, path_2)\n",
        "\n",
        "path_1 = '/content/HistopatologyBreastCancerM400X_unhas_makassar.zip/HistopatologyBreastCancerM400X/test/benign'\n",
        "path_2 = '/content/HistopatologyBreastCancerM400X_unhas_makassar.zip/HistopatologyBreastCancerM400X/test/malignant'\n",
        "count_class(path_1, path_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cI_zTtDou69v",
        "outputId": "9ff7c2a9-3424-4722-b8f1-fa1ced7891d2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 1: 296\n",
            "Class 2: 621\n",
            "Total: 917\n",
            "Class 1: 75\n",
            "Class 2: 156\n",
            "Total: 231\n",
            "Class 1: 176\n",
            "Class 2: 369\n",
            "Total: 545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Build Model Function"
      ],
      "metadata": {
        "id": "Nr2R8XVTRfoA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code defines a function called `build_model_xxxx` that constructs a deep learning model, which is pre-trained on the ImageNet dataset. This function is used to build and compile a model tailored for a specific classification task.\n",
        "\n",
        "### Inputs:\n",
        "- `num_classes`: The number of output classes for the classification task. This determines the size of the final dense layer.\n",
        "- `learning_rate`: The learning rate for the Adam optimizer (default is 0.001). It controls the step size during gradient descent.\n",
        "- `freeze`: A boolean flag indicating whether to freeze the layers of the pre-trained Xception base model (default is `True`). When layers are frozen, their weights will not be updated during training.\n",
        "\n",
        "### Functionality:\n",
        "The function:\n",
        "1. Loads the pre-trained model without the top (fully-connected) layer.\n",
        "2. Adds a global average pooling layer to reduce the spatial dimensions of the output from the base model.\n",
        "3. Adds a fully-connected layer with 1024 units and ReLU activation.\n",
        "4. Adds a final dense layer with a softmax activation function for multi-class classification, where the number of units equals `num_classes`.\n",
        "5. Optionally freezes the layers of the Xception base model to prevent their weights from being updated during training, allowing only the added layers to be trained.\n",
        "6. Compiles the model using the Adam optimizer, categorical cross-entropy loss, and accuracy as a metric.\n",
        "\n",
        "The returned model is ready to be trained on your dataset.\n"
      ],
      "metadata": {
        "id": "wpLoL1vILl2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# Xception\n",
        "def build_model_xception(num_classes, learning_rate=0.001, freeze=True):\n",
        "    base_model = Xception(weights='imagenet', include_top=False)  # Load the Xception model without the top layer\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)  # Add a global spatial average pooling layer\n",
        "    x = Dense(1024, activation='relu')(x)  # Add a fully-connected layer\n",
        "    predictions = Dense(num_classes, activation='softmax')(x)  # Add a logistic layer for classification\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    # Freeze the layers of the base model\n",
        "    if freeze:\n",
        "      for layer in base_model.layers:\n",
        "          layer.trainable = False\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# ResNet50V2\n",
        "from tensorflow.keras.applications import ResNet50V2\n",
        "def build_model_resnet50v2(num_classes, learning_rate=0.001, freeze=True):\n",
        "    base_model = ResNet50V2(weights='imagenet', include_top=False)  # Load the ResNet50V2 model without the top layer\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)  # Add a global spatial average pooling layer\n",
        "    x = Dense(1024, activation='relu')(x)  # Add a fully-connected layer\n",
        "    predictions = Dense(num_classes, activation='softmax')(x)  # Add a logistic layer for classification\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    # Freeze the layers of the base model\n",
        "    if freeze:\n",
        "      for layer in base_model.layers:\n",
        "          layer.trainable = False\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# InceptionResNetV2\n",
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "def build_model_inceptionresnetv2(num_classes, learning_rate=0.001, freeze=True):\n",
        "    base_model = InceptionResNetV2(weights='imagenet', include_top=False)  # Load the InceptionResNetV2 model without the top layer\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)  # Add a global spatial average pooling layer\n",
        "    x = Dense(1024, activation='relu')(x)  # Add a fully-connected layer\n",
        "    predictions = Dense(num_classes, activation='softmax')(x)  # Add a logistic layer for classification\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    # Freeze the layers of the base model\n",
        "    if freeze:\n",
        "      for layer in base_model.layers:\n",
        "          layer.trainable = False\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# DenseNet201\n",
        "from tensorflow.keras.applications import DenseNet201\n",
        "def build_model_densenet201(num_classes, learning_rate=0.001, freeze=True):\n",
        "    base_model = DenseNet201(weights='imagenet', include_top=False)  # Load the DenseNet201 model without the top layer\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)  # Add a global spatial average pooling layer\n",
        "    x = Dense(1024, activation='relu')(x)  # Add a fully-connected layer\n",
        "    predictions = Dense(num_classes, activation='softmax')(x)  # Add a logistic layer for classification\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    # Freeze the layers of the base model\n",
        "    if freeze:\n",
        "      for layer in base_model.layers:\n",
        "          layer.trainable = False\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# EfficientNetB4\n",
        "from tensorflow.keras.applications import EfficientNetB4\n",
        "def build_model_efficientnetb4(num_classes, learning_rate=0.001, freeze=True):\n",
        "    base_model = EfficientNetB4(weights='imagenet', include_top=False)  # Load the EfficientNetB4 model without the top layer\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)  # Add a global spatial average pooling layer\n",
        "    x = Dense(1024, activation='relu')(x)  # Add a fully-connected layer\n",
        "    predictions = Dense(num_classes, activation='softmax')(x)  # Add a logistic layer for classification\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    # Freeze the layers of the base model\n",
        "    if freeze:\n",
        "      for layer in base_model.layers:\n",
        "          layer.trainable = False\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# EfficientNetV2S\n",
        "from tensorflow.keras.applications import EfficientNetV2S\n",
        "def build_model_efficientnetv2s(num_classes, learning_rate=0.001, freeze=True):\n",
        "    base_model = EfficientNetV2S(weights='imagenet', include_top=False)  # Load the EfficientNetV2S model without the top layer\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)  # Add a global spatial average pooling layer\n",
        "    x = Dense(1024, activation='relu')(x)  # Add a fully-connected layer\n",
        "    predictions = Dense(num_classes, activation='softmax')(x)  # Add a logistic layer for classification\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    # Freeze the layers of the base model\n",
        "    if freeze:\n",
        "      for layer in base_model.layers:\n",
        "          layer.trainable = False\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "PntXD5lUaGsN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Model Training Function"
      ],
      "metadata": {
        "id": "aRHO2XeXRlYD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code defines a function called `train_model` that trains a deep learning model using image data from specified directories. The function handles data augmentation, model training, and the implementation of callbacks for early stopping and saving the best model.\n",
        "\n",
        "### Inputs:\n",
        "- `model`: The deep learning model to be trained, typically created using a function like `build_model_xception`.\n",
        "- `train_data_dir`: The directory containing the training data, organized by class subdirectories.\n",
        "- `validation_data_dir`: The directory containing the validation data, also organized by class subdirectories.\n",
        "- `batch_size`: The number of samples processed before the model's weights are updated (default is 32).\n",
        "- `epochs`: The number of complete passes through the training dataset (default is 10).\n",
        "- `input_size`: The target size for resizing images before they are fed into the model (default is 299x299, which is suitable for the Xception model).\n",
        "\n",
        "### Functionality:\n",
        "1. **Data Augmentation**: Applies random transformations (like shearing, zooming, and flipping) to the training images to increase the diversity of the training set and reduce overfitting.\n",
        "2. **Data Generators**: Creates generators for the training and validation datasets that load images in batches, apply preprocessing, and resize them to the specified `input_size`.\n",
        "3. **Callbacks**:\n",
        "   - **ModelCheckpoint**: Saves the model with the best validation loss during training.\n",
        "   - **EarlyStopping**: Stops training if the validation loss doesn't improve for a specified number of epochs (patience is set to 5).\n",
        "4. **Training**: The model is trained using the training data generator and evaluated on the validation data generator. The training history, which includes metrics like loss and accuracy over epochs, is returned.\n",
        "\n",
        "This function is used to train the model on your dataset, with automatic handling of image data and model saving.\n"
      ],
      "metadata": {
        "id": "2XdlyIzlMVun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_data_dir, validation_data_dir, batch_size=32, epochs=10, input_size=(299, 299)):\n",
        "    # Data augmentation for training data\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        preprocessing_function=preprocess_input,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True)\n",
        "\n",
        "    # Data augmentation for validation data\n",
        "    validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "    # Generators for training and validation data\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=input_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "\n",
        "    validation_generator = validation_datagen.flow_from_directory(\n",
        "        validation_data_dir,\n",
        "        target_size=input_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "\n",
        "    # Callbacks for saving the best model and early stopping\n",
        "    checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True, mode='min')\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, mode='min')\n",
        "\n",
        "    # Training the model\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=train_generator.samples // batch_size,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=validation_generator.samples // batch_size,\n",
        "        epochs=epochs,\n",
        "        callbacks=[checkpoint, early_stopping])\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "C7RSKgF2b2T9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Test Model Function"
      ],
      "metadata": {
        "id": "y8Cyd8c2Rqtg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code defines a function called `test_model` that evaluates a trained deep learning model on a test dataset. It uses data augmentation specific to the Xception model's preprocessing and returns the model's performance in terms of loss and accuracy on the test data.\n",
        "\n",
        "### Inputs:\n",
        "- `model`: The trained deep learning model to be evaluated, typically loaded or passed in after training.\n",
        "- `test_data_dir`: The directory containing the test data, organized by class subdirectories.\n",
        "- `batch_size`: The number of samples processed at once during evaluation (default is 32).\n",
        "- `input_size`: The target size for resizing test images before they are fed into the model (default is 299x299, which is suitable for the Xception model).\n",
        "\n",
        "### Functionality:\n",
        "1. **Data Augmentation**: Applies Xception's preprocessing function to the test images to ensure they are processed in the same way as the training and validation data.\n",
        "2. **Test Data Generator**: Creates a generator that loads the test images in batches, applies preprocessing, resizes them to the specified `input_size`, and ensures the data is not shuffled (to maintain order for evaluation).\n",
        "3. **Model Evaluation**: Evaluates the model on the test data using the generator and prints out the test loss and accuracy.\n",
        "\n",
        "This function is used to assess how well the model generalizes to unseen data, providing metrics that summarize its performance.\n"
      ],
      "metadata": {
        "id": "BKN4lCD7MfOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, test_data_dir, batch_size=32, input_size=(299, 299)):\n",
        "    # Data augmentation for test data with Xception preprocessing\n",
        "    test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "    # Generator for test data\n",
        "    test_generator = test_datagen.flow_from_directory(\n",
        "        test_data_dir,\n",
        "        target_size=input_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False)\n",
        "\n",
        "    # Load the best model\n",
        "    scores = model.evaluate(test_generator)\n",
        "    print(f\"Test Loss: {scores[0]}\")\n",
        "    print(f\"Test Accuracy: {scores[1]}\")"
      ],
      "metadata": {
        "id": "eBP7VE8DebPN"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Sample Run"
      ],
      "metadata": {
        "id": "VbHPtVa3Rv9b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section of code sets up the necessary parameters for training a deep learning model using the Xception architecture and then initiates the training process.\n",
        "\n",
        "### Parameters:\n",
        "- `num_classes`: The number of output classes for the classification task, which is set to 2 for binary classification (e.g., benign vs. malignant).\n",
        "- `train_data_dir`: The directory path containing the training images, organized by class subdirectories.\n",
        "- `validation_data_dir`: The directory path containing the validation images, also organized by class subdirectories.\n",
        "- `test_data_dir`: The directory path containing the test images, organized similarly to the training and validation directories.\n",
        "- `batch_size`: The number of images processed in each training step (default is 32).\n",
        "- `epochs`: The number of times the model will pass through the entire training dataset (default is 10).\n",
        "\n",
        "### How to train a model:\n",
        "1. Import the preprocessor:\n",
        "  - e.g. `from tensorflow.keras.applications.xception import preprocess_input`\n",
        "2. Build the model:\n",
        "  - e.g. `model = build_model_xception(num_classes, learning_rate=0.001, freeze=True)`\n",
        "3. Train the model:\n",
        "  - e.g. `history = train_model(model, train_data_dir, validation_data_dir, batch_size, epochs, input_size=(299,299))`\n",
        "\n",
        "The model will be saved as `best_model.keras`. Rename the model or download it before doing another training run"
      ],
      "metadata": {
        "id": "zfClMk9WNNIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameters\n",
        "num_classes = 2  # For binary classification\n",
        "train_data_dir = '/content/HistopatologyBreastCancerM400X_unhas_makassar.zip/HistopatologyBreastCancerM400X/train'\n",
        "validation_data_dir = '/content/HistopatologyBreastCancerM400X_unhas_makassar.zip/HistopatologyBreastCancerM400X/validation'\n",
        "test_data_dir = '/content/HistopatologyBreastCancerM400X_unhas_makassar.zip/HistopatologyBreastCancerM400X/test'\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "\n",
        "\n",
        "# -- Xception --\n",
        "from tensorflow.keras.applications.xception import preprocess_input #Xception\n",
        "input_size = (299, 299)  # Xception expects 299x299 input size\n",
        "model = build_model_xception(num_classes, learning_rate=0.001, freeze=True)\n",
        "history = train_model(model, train_data_dir, validation_data_dir, batch_size, epochs, input_size)\n",
        "\n",
        "# -- ResNet50V2 --\n",
        "# from tensorflow.keras.applications.resnet_v2 import preprocess_input #ResNet50V2\n",
        "# input_size = (224, 224)  # ResNet50v2 expects 224x224 input size\n",
        "# model = build_model_resnet50v2(num_classes, learning_rate=0.001, freeze=True)\n",
        "# history = train_model(model, train_data_dir, validation_data_dir, batch_size, epochs, input_size)\n",
        "\n",
        "# -- InceptionResNetV2 --\n",
        "# from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input #InceptionResNetV2\n",
        "# input_size = (299, 299)  # InceptionResNetV2 expects 299x299 input size\n",
        "# model = build_model_inceptionresnetv2(num_classes, learning_rate=0.001, freeze=True)\n",
        "# history = train_model(model, train_data_dir, validation_data_dir, batch_size, epochs, input_size)\n",
        "\n",
        "# -- DenseNet201 --\n",
        "# from tensorflow.keras.applications.densenet import preprocess_input #DenseNet201\n",
        "# input_size = (224, 224)  # DenseNet201 expects 224x224 input size\n",
        "# model = build_model_densenet201(num_classes, learning_rate=0.001, freeze=True)\n",
        "# history = train_model(model, train_data_dir, validation_data_dir, batch_size, epochs, input_size)\n",
        "\n",
        "# -- EfficientNetB4 --\n",
        "# from tensorflow.keras.applications.efficientnet import preprocess_input #EfficientNetB4\n",
        "# input_size = (384, 380)  # EfficientNetB4 expects 384x380 input size\n",
        "# model = build_model_efficientnetb4(num_classes, learning_rate=0.001, freeze=True)\n",
        "# history = train_model(model, train_data_dir, validation_data_dir, batch_size, epochs, input_size)\n",
        "\n",
        "# -- EfficientNetV2S --\n",
        "# from tensorflow.keras.applications.efficientnet_v2 import preprocess_input #EfficientNetV2S\n",
        "# input_size = (384, 384)  # EfficientNetV2S expects 384x384 input size\n",
        "# model = build_model_efficientnetv2s(num_classes, learning_rate=0.001, freeze=True)\n",
        "# history = train_model(model, train_data_dir, validation_data_dir, batch_size, epochs, input_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4LsQKiDeifF",
        "outputId": "37904d94-b95d-4a30-eb7b-467aca27f343"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-s_notop.h5\n",
            "\u001b[1m82420632/82420632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n",
            "Found 917 images belonging to 2 classes.\n",
            "Found 231 images belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 2s/step - accuracy: 0.7559 - loss: 0.6230 - val_accuracy: 0.8705 - val_loss: 0.3751\n",
            "Epoch 2/10\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 375ms/step - accuracy: 0.8750 - loss: 0.3073 - val_accuracy: 0.8571 - val_loss: 0.3230\n",
            "Epoch 3/10\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.8859 - loss: 0.2957 - val_accuracy: 0.8571 - val_loss: 0.3836\n",
            "Epoch 4/10\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9062 - loss: 0.2432 - val_accuracy: 0.8571 - val_loss: 0.2932\n",
            "Epoch 5/10\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.9054 - loss: 0.2537 - val_accuracy: 0.8214 - val_loss: 0.4368\n",
            "Epoch 6/10\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9062 - loss: 0.2605 - val_accuracy: 0.7143 - val_loss: 0.3691\n",
            "Epoch 7/10\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.9274 - loss: 0.2132 - val_accuracy: 0.8661 - val_loss: 0.3191\n",
            "Epoch 8/10\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7500 - loss: 0.4462 - val_accuracy: 0.7143 - val_loss: 0.8137\n",
            "Epoch 9/10\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.9161 - loss: 0.2366 - val_accuracy: 0.8616 - val_loss: 0.3078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How to Evaluate a model:\n",
        "1. Import the preprocessor:\n",
        "  - e.g. `from tensorflow.keras.applications.xception import preprocess_input`\n",
        "2. Build the model:\n",
        "  - e.g. `model = build_model_xception(num_classes, learning_rate=0.001, freeze=True)`\n",
        "3. Load the weights:\n",
        "  - e.g. `model.load_weights('/content/best_model_xception.keras')`\n",
        "4. Test the model:\n",
        "  - e.g. `test_model(model, test_data_dir, batch_size=32, input_size=(299, 299))`\n",
        "\n",
        "The performance will be printed directly. Please make sure to import the appropriate preprocessor before running `test_model`. Make sure the model built using `build_model_xxxx` matches with the model you want."
      ],
      "metadata": {
        "id": "UomX0mOHOZY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -- Xception --\n",
        "from tensorflow.keras.applications.xception import preprocess_input\n",
        "input_size = (299, 299)\n",
        "model = build_model_xception(num_classes, learning_rate=0.001, freeze=True)\n",
        "model.load_weights('/content/best_model_xception.keras')\n",
        "test_model(model, test_data_dir, batch_size=32, input_size=input_size)\n",
        "\n",
        "# -- ResNet50V2 --\n",
        "from tensorflow.keras.applications.resnet_v2 import preprocess_input #ResNet50V2\n",
        "model = build_model_resnet50v2(num_classes, learning_rate=0.001, freeze=True)\n",
        "model.load_weights('/content/best_model_resnet50v2.keras')\n",
        "input_size = (224, 224)  # ResNet50v2 expects 224x224 input size\n",
        "test_model(model, test_data_dir, batch_size=32, input_size=input_size)\n",
        "\n",
        "# -- InceptionResNetV2 --\n",
        "from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input #InceptionResNetV2\n",
        "input_size = (299, 299)  # InceptionResNetV2 expects 299x299 input size\n",
        "model = build_model_inceptionresnetv2(num_classes, learning_rate=0.001, freeze=True)\n",
        "model.load_weights('/content/best_model_inceptionresnetv2.keras')\n",
        "test_model(model, test_data_dir, batch_size=32, input_size=input_size)\n",
        "\n",
        "# -- DenseNet201 --\n",
        "from tensorflow.keras.applications.densenet import preprocess_input #DenseNet201\n",
        "input_size = (224, 224)  # DenseNet201 expects 224x224 input size\n",
        "model = build_model_densenet201(num_classes, learning_rate=0.001, freeze=True)\n",
        "model.load_weights('/content/best_model_densenet201.keras')\n",
        "test_model(model, test_data_dir, batch_size=32, input_size=input_size)\n",
        "\n",
        "# -- EfficientNetB4 --\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input #EfficientNetB4\n",
        "input_size = (384, 380)  # EfficientNetB4 expects 384x380 input size\n",
        "model = build_model_efficientnetb4(num_classes, learning_rate=0.001, freeze=True)\n",
        "model.load_weights('/content/best_model_efficientnetb4.keras')\n",
        "test_model(model, test_data_dir, batch_size=32, input_size=input_size)\n",
        "\n",
        "# -- EfficientNetV2S --\n",
        "from tensorflow.keras.applications.efficientnet_v2 import preprocess_input #EfficientNetV2S\n",
        "input_size = (384, 384)  # EfficientNetV2S expects 384x384 input size\n",
        "model = build_model_efficientnetv2s(num_classes, learning_rate=0.001, freeze=True)\n",
        "model.load_weights('/content/best_model_efficientnetv2s.keras')\n",
        "test_model(model, test_data_dir, batch_size=32, input_size=input_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWMehhdwPK7R",
        "outputId": "fb82e670-6c22-4954-b716-5ffdcda0dbce"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 545 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 10 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 449ms/step - accuracy: 0.7065 - loss: 0.5790\n",
            "Test Loss: 0.43257570266723633\n",
            "Test Accuracy: 0.8275229334831238\n",
            "Found 545 images belonging to 2 classes.\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 437ms/step - accuracy: 0.7990 - loss: 0.4516\n",
            "Test Loss: 0.34670519828796387\n",
            "Test Accuracy: 0.853210985660553\n",
            "Found 545 images belonging to 2 classes.\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 619ms/step - accuracy: 0.6133 - loss: 0.8042\n",
            "Test Loss: 0.4448402225971222\n",
            "Test Accuracy: 0.7981651425361633\n",
            "Found 545 images belonging to 2 classes.\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 736ms/step - accuracy: 0.8460 - loss: 0.3946\n",
            "Test Loss: 0.2961312532424927\n",
            "Test Accuracy: 0.8880733847618103\n",
            "Found 545 images belonging to 2 classes.\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 721ms/step - accuracy: 0.5519 - loss: 0.8069\n",
            "Test Loss: 0.5145378708839417\n",
            "Test Accuracy: 0.7596330046653748\n",
            "Found 545 images belonging to 2 classes.\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 702ms/step - accuracy: 0.7696 - loss: 0.4711\n",
            "Test Loss: 0.3012269139289856\n",
            "Test Accuracy: 0.8660550713539124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How to fine-tune a model:\n",
        "1. Import the preprocessor:\n",
        "  - e.g. `from tensorflow.keras.applications.xception import preprocess_input`\n",
        "2. Build the model with smaller `learning_rate` and set `freeze` to false:\n",
        "  - e.g. `model = build_model_xception(num_classes, learning_rate=0.0001, freeze=True)`\n",
        "3. Load the weights:\n",
        "  - e.g. `model.load_weights('/content/best_model_xception.keras')`\n",
        "4. Train the model:\n",
        "  - e.g. `history = train_model(model, train_data_dir, validation_data_dir, batch_size, epochs, input_size=(299,299))`\n",
        "  \n",
        "The model will be saved as `best_model.keras`. Rename the model or download it before doing another training run."
      ],
      "metadata": {
        "id": "EvaJfMfBP0Hk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # -- Xception --\n",
        "# from tensorflow.keras.applications.xception import preprocess_input\n",
        "# model = build_model_xception(num_classes, learning_rate=0.0001, freeze=False)\n",
        "# model.load_weights('/content/best_model_xception.keras')\n",
        "# input_size = (299, 299)\n",
        "# history = train_model(model, train_data_dir, validation_data_dir, batch_size, epochs, input_size=input_size)\n",
        "\n",
        "# # -- ResNet50V2 --\n",
        "# from tensorflow.keras.applications.resnet_v2 import preprocess_input #ResNet50V2\n",
        "# model = build_model_resnet50v2(num_classes, learning_rate=0.00001, freeze=False)\n",
        "# model.load_weights('/content/best_model_resnet50v2.keras')\n",
        "# input_size = (224, 224)  # ResNet50v2 expects 224x224 input size\n",
        "# history = train_model(model, train_data_dir, validation_data_dir, batch_size, epochs, input_size=input_size)\n",
        "\n",
        "# # -- InceptionResNetV2 --\n",
        "# from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input #InceptionResNetV2\n",
        "# input_size = (299, 299)  # InceptionResNetV2 expects 299x299 input size\n",
        "# model = build_model_inceptionresnetv2(num_classes, learning_rate=0.0001, freeze=False)\n",
        "# model.load_weights('/content/best_model_inceptionresnetv2.keras')\n",
        "# history = train_model(model, train_data_dir, validation_data_dir, batch_size, epochs, input_size=input_size)\n",
        "\n",
        "# # -- DenseNet201 --\n",
        "# from tensorflow.keras.applications.densenet import preprocess_input #DenseNet201\n",
        "# input_size = (224, 224)  # DenseNet201 expects 224x224 input size\n",
        "# model = build_model_densenet201(num_classes, learning_rate=0.0001, freeze=False)\n",
        "# model.load_weights('/content/best_model_densenet201.keras')\n",
        "# history = train_model(model, train_data_dir, validation_data_dir, batch_size, epochs, input_size=input_size)\n",
        "\n",
        "# # -- EfficientNetB4 --\n",
        "# from tensorflow.keras.applications.efficientnet import preprocess_input #EfficientNetB4\n",
        "# input_size = (384, 380)  # EfficientNetB4 expects 384x380 input size\n",
        "# model = build_model_efficientnetb4(num_classes, learning_rate=0.0001, freeze=False)\n",
        "# model.load_weights('/content/best_model_efficientnetb4.keras')\n",
        "# history = train_model(model, train_data_dir, validation_data_dir, batch_size, epochs, input_size=input_size)\n",
        "\n",
        "# -- EfficientNetV2S --\n",
        "from tensorflow.keras.applications.efficientnet_v2 import preprocess_input #EfficientNetV2S\n",
        "input_size = (384, 384)  # EfficientNetV2S expects 384x384 input size\n",
        "model = build_model_efficientnetv2s(num_classes, learning_rate=0.0001, freeze=False)\n",
        "model.load_weights('/content/best_model_efficientnetv2s.keras')\n",
        "history = train_model(model, train_data_dir, validation_data_dir, batch_size, epochs, input_size=input_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63G2-WtF7Zve",
        "outputId": "fcd3cb75-8501-4286-8ce9-596b2e562c48"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 917 images belonging to 2 classes.\n",
            "Found 231 images belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 5s/step - accuracy: 0.6816 - loss: 0.5927 - val_accuracy: 0.9018 - val_loss: 0.2796\n",
            "Epoch 2/10\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 211ms/step - accuracy: 0.9062 - loss: 0.2387 - val_accuracy: 0.7143 - val_loss: 0.4806\n",
            "Epoch 3/10\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.9319 - loss: 0.1750 - val_accuracy: 0.8795 - val_loss: 0.2477\n",
            "Epoch 4/10\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 0.0317 - val_accuracy: 1.0000 - val_loss: 0.0225\n",
            "Epoch 5/10\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.9668 - loss: 0.0970 - val_accuracy: 0.9152 - val_loss: 0.2236\n",
            "Epoch 6/10\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0623 - val_accuracy: 1.0000 - val_loss: 0.0336\n",
            "Epoch 7/10\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.9827 - loss: 0.0616 - val_accuracy: 0.9018 - val_loss: 0.2962\n",
            "Epoch 8/10\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 0.9688 - loss: 0.0591 - val_accuracy: 1.0000 - val_loss: 0.0167\n",
            "Epoch 9/10\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.9725 - loss: 0.0716 - val_accuracy: 0.9241 - val_loss: 0.2100\n",
            "Epoch 10/10\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0146 - val_accuracy: 0.8571 - val_loss: 0.1806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -- Xception --\n",
        "from tensorflow.keras.applications.xception import preprocess_input\n",
        "input_size = (299, 299)\n",
        "model = build_model_xception(num_classes, learning_rate=0.0001, freeze=False)\n",
        "model.load_weights('/content/best_model_xception_finetuned.keras')\n",
        "test_model(model, test_data_dir, batch_size=32, input_size=input_size)\n",
        "\n",
        "# -- ResNet50V2 --\n",
        "from tensorflow.keras.applications.resnet_v2 import preprocess_input #ResNet50V2\n",
        "model = build_model_resnet50v2(num_classes, learning_rate=0.0001, freeze=False)\n",
        "model.load_weights('/content/best_model_resnet50v2_finetuned.keras')\n",
        "input_size = (224, 224)  # ResNet50v2 expects 224x224 input size\n",
        "test_model(model, test_data_dir, batch_size=32, input_size=input_size)\n",
        "\n",
        "# -- InceptionResNetV2 --\n",
        "from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input #InceptionResNetV2\n",
        "input_size = (299, 299)  # InceptionResNetV2 expects 299x299 input size\n",
        "model = build_model_inceptionresnetv2(num_classes, learning_rate=0.0001, freeze=False)\n",
        "model.load_weights('/content/best_model_inceptionresnetv2_finetuned.keras')\n",
        "test_model(model, test_data_dir, batch_size=32, input_size=input_size)\n",
        "\n",
        "# -- DenseNet201 --\n",
        "from tensorflow.keras.applications.densenet import preprocess_input #DenseNet201\n",
        "input_size = (224, 224)  # DenseNet201 expects 224x224 input size\n",
        "model = build_model_densenet201(num_classes, learning_rate=0.0001, freeze=False)\n",
        "model.load_weights('/content/best_model_densenet201_finetuned.keras')\n",
        "test_model(model, test_data_dir, batch_size=32, input_size=input_size)\n",
        "\n",
        "# -- EfficientNetB4 --\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input #EfficientNetB4\n",
        "input_size = (384, 380)  # EfficientNetB4 expects 384x380 input size\n",
        "model = build_model_efficientnetb4(num_classes, learning_rate=0.0001, freeze=False)\n",
        "model.load_weights('/content/best_model_efficientnetb4_finetuned.keras')\n",
        "test_model(model, test_data_dir, batch_size=32, input_size=input_size)\n",
        "\n",
        "# -- EfficientNetV2S --\n",
        "from tensorflow.keras.applications.efficientnet_v2 import preprocess_input #EfficientNetV2S\n",
        "input_size = (384, 384)  # EfficientNetV2S expects 384x384 input size\n",
        "model = build_model_efficientnetv2s(num_classes, learning_rate=0.0001, freeze=False)\n",
        "model.load_weights('/content/best_model_efficientnetv2s_finetuned.keras')\n",
        "test_model(model, test_data_dir, batch_size=32, input_size=input_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhir1b2ERH0I",
        "outputId": "6af89a81-4be3-499d-d824-c564d81ecedf"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 545 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 318 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 461ms/step - accuracy: 0.8485 - loss: 0.7053\n",
            "Test Loss: 0.3737509846687317\n",
            "Test Accuracy: 0.9192660450935364\n",
            "Found 545 images belonging to 2 classes.\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 452ms/step - accuracy: 0.8112 - loss: 0.4700\n",
            "Test Loss: 0.32640472054481506\n",
            "Test Accuracy: 0.8770642280578613\n",
            "Found 545 images belonging to 2 classes.\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 641ms/step - accuracy: 0.6538 - loss: 1.4923\n",
            "Test Loss: 0.7720240950584412\n",
            "Test Accuracy: 0.8220183253288269\n",
            "Found 545 images belonging to 2 classes.\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 726ms/step - accuracy: 0.8248 - loss: 0.8370\n",
            "Test Loss: 0.4183472990989685\n",
            "Test Accuracy: 0.9045871496200562\n",
            "Found 545 images belonging to 2 classes.\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 718ms/step - accuracy: 0.8573 - loss: 0.3561\n",
            "Test Loss: 0.23928412795066833\n",
            "Test Accuracy: 0.9045871496200562\n",
            "Found 545 images belonging to 2 classes.\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 702ms/step - accuracy: 0.9382 - loss: 0.2153\n",
            "Test Loss: 0.19323325157165527\n",
            "Test Accuracy: 0.9376146793365479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Ensemble Model Function"
      ],
      "metadata": {
        "id": "enS2c4IItsE3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section of code includes functions for generating model predictions, combining probabilities (in case of an ensemble), and evaluating model accuracy. Each function is designed to handle specific tasks in the evaluation process of a deep learning model.\n",
        "\n",
        "### Functions:\n",
        "\n",
        "1. **`generate_output_probability`**:\n",
        "   - **Purpose:** To generate predicted probabilities for the test dataset using a trained model.\n",
        "   - **Inputs:**\n",
        "     - `model`: The trained deep learning model used for making predictions.\n",
        "     - `test_data_dir`: The directory containing the test images, organized by class subdirectories.\n",
        "     - `batch_size`: The number of images processed in each prediction step (default is 32).\n",
        "     - `input_size`: The target size for resizing images before they are fed into the model (default is 299x299).\n",
        "   - **Output:** A numpy array of predicted probabilities for each class.\n",
        "\n",
        "2. **`combine_output_probability`**:\n",
        "   - **Purpose:** To combine probabilities from multiple models in an ensemble.\n",
        "   - **Input:**\n",
        "     - `probabilities`: A list or array of predicted probabilities from different models.\n",
        "   - **Output:** The average of the probabilities from all models, which represents the combined prediction.\n",
        "\n",
        "3. **`evaluate_accuracy`**:\n",
        "   - **Purpose:** To calculate the accuracy of the model based on the predicted probabilities and true labels from the test dataset.\n",
        "   - **Inputs:**\n",
        "     - `probability`: The array of predicted probabilities for the test dataset.\n",
        "     - `test_data_dir`: The directory containing the test images, organized by class subdirectories.\n",
        "     - `batch_size`: The number of images processed in each evaluation step (default is 32).\n",
        "     - `input_size`: The target size for resizing images before they are fed into the model (default is 299x299).\n",
        "   - **Output:** The accuracy score, which indicates the proportion of correctly classified test samples.\n",
        "\n",
        "These functions are essential for evaluating the performance of your model or ensemble, providing insights into how well your model generalizes to new, unseen data.\n"
      ],
      "metadata": {
        "id": "W90UJMkpgFM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def generate_output_probability(model, test_data_dir, batch_size=32, input_size=(299, 299)):\n",
        "    test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "    # Generator for test data\n",
        "    test_generator = test_datagen.flow_from_directory(\n",
        "        test_data_dir,\n",
        "        target_size=input_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False)\n",
        "\n",
        "    # Generate probabilities\n",
        "    probabilities = model.predict(test_generator)\n",
        "\n",
        "    return probabilities\n",
        "\n",
        "def combine_output_probability(probabilities):\n",
        "    # Combine probabilities from all models\n",
        "    combined_probabilities = np.mean(probabilities, axis=0)\n",
        "\n",
        "    return combined_probabilities\n",
        "\n",
        "def evaluate_accuracy(probability, test_data_dir, batch_size=32, input_size=(299, 299)):\n",
        "    test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "    # Generator for test data\n",
        "    test_generator = test_datagen.flow_from_directory(\n",
        "        test_data_dir,\n",
        "        target_size=input_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False)\n",
        "\n",
        "    # Get the true labels\n",
        "    true_labels = test_generator.classes\n",
        "\n",
        "    # Get the predicted labels\n",
        "    predicted_labels = np.argmax(probability, axis=1)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "u_5NQmO5RkXQ"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Sample Run"
      ],
      "metadata": {
        "id": "F2RKDcAXf6qO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How to Evaluate ensemble of models:\n",
        "1. Import the preprocessor:\n",
        "  - e.g. `from tensorflow.keras.applications.xception import preprocess_input`\n",
        "2. Build the model:\n",
        "  - e.g. `model = build_model_xception(num_classes, learning_rate=0.001, freeze=True)`\n",
        "3. Load the weights:\n",
        "  - e.g. `model.load_weights('/content/best_model_xception_finetuned.keras')`\n",
        "4. Generate probabilities:\n",
        "  - e.g. `probability_xception = generate_output_probability(model, test_data_dir, batch_size=32, input_size=input_size)`\n",
        "5. Combine the probabilities:\n",
        "  - e.g. `combined_probabilities = combine_output_probability([probability_xception, probability_resnet50v2])`\n",
        "6. Evaluate the accuracy:\n",
        "  - e.g.`accuracy = evaluate_accuracy(combined_probabilities, test_data_dir, batch_size=32, input_size=input_size)`"
      ],
      "metadata": {
        "id": "r77wYaKvgyZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.xception import preprocess_input\n",
        "input_size = (299, 299)\n",
        "model = build_model_xception(num_classes, learning_rate=0.0001, freeze=False)\n",
        "model.load_weights('/content/best_model_xception_finetuned.keras')\n",
        "probability_xception = generate_output_probability(model, test_data_dir, batch_size=32, input_size=input_size)\n",
        "\n",
        "from tensorflow.keras.applications.resnet_v2 import preprocess_input #ResNet50V2\n",
        "input_size = (224, 224)  # ResNet50v2 expects 224x224 input size\n",
        "model = build_model_resnet50v2(num_classes, learning_rate=0.00001, freeze=False)\n",
        "model.load_weights('/content/best_model_resnet50v2_finetuned.keras')\n",
        "probability_resnet50v2 = generate_output_probability(model, test_data_dir, batch_size=32, input_size=input_size)\n",
        "\n",
        "from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input #InceptionResNetV2\n",
        "input_size = (299, 299)  # InceptionResNetV2 expects 299x299 input size\n",
        "model = build_model_inceptionresnetv2(num_classes, learning_rate=0.0001, freeze=False)\n",
        "model.load_weights('/content/best_model_inceptionresnetv2_finetuned.keras')\n",
        "probability_inceptionresnetv2 = generate_output_probability(model, test_data_dir, batch_size=32, input_size=input_size)\n",
        "\n",
        "from tensorflow.keras.applications.densenet import preprocess_input #DenseNet201\n",
        "input_size = (224, 224)  # DenseNet201 expects 224x224 input size\n",
        "model = build_model_densenet201(num_classes, learning_rate=0.0001, freeze=False)\n",
        "model.load_weights('/content/best_model_densenet201_finetuned.keras')\n",
        "probability_densenet201 = generate_output_probability(model, test_data_dir, batch_size=32, input_size=input_size)\n",
        "\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input #EfficientNetB4\n",
        "input_size = (384, 380)  # EfficientNetB4 expects 384x380\n",
        "model = build_model_efficientnetb4(num_classes, learning_rate=0.0001, freeze=False)\n",
        "model.load_weights('/content/best_model_efficientnetb4_finetuned.keras')\n",
        "probability_efficientnetb4 = generate_output_probability(model, test_data_dir, batch_size=32, input_size=input_size)\n",
        "\n",
        "from tensorflow.keras.applications.efficientnet_v2 import preprocess_input #EfficientNetV2S\n",
        "input_size = (384, 384)  # EfficientNetV2S expects 384x384\n",
        "model = build_model_efficientnetv2s(num_classes, learning_rate=0.0001, freeze=False)\n",
        "model.load_weights('/content/best_model_efficientnetv2s_finetuned.keras')\n",
        "probability_efficientnetv2s = generate_output_probability(model, test_data_dir, batch_size=32, input_size=input_size)\n",
        "\n",
        "# combine the probabilities\n",
        "combined_probabilities = combine_output_probability(\n",
        "    [probability_xception,\n",
        "     probability_resnet50v2,\n",
        "     probability_inceptionresnetv2,\n",
        "     probability_densenet201,\n",
        "     probability_efficientnetb4,\n",
        "     probability_efficientnetv2s]\n",
        ")\n",
        "\n",
        "# evaluate the accuracies\n",
        "accuracy = evaluate_accuracy(combined_probabilities, test_data_dir, batch_size=32, input_size=input_size)\n",
        "print(accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hp-mL-9GTFpX",
        "outputId": "56988eb6-b755-47a5-bdfa-7df19cfd9e56"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 545 images belonging to 2 classes.\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 481ms/step\n",
            "Found 545 images belonging to 2 classes.\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 503ms/step\n",
            "Found 545 images belonging to 2 classes.\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 899ms/step\n",
            "Found 545 images belonging to 2 classes.\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step\n",
            "Found 545 images belonging to 2 classes.\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 924ms/step\n",
            "Found 545 images belonging to 2 classes.\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 932ms/step\n",
            "Found 545 images belonging to 2 classes.\n",
            "0.926605504587156\n"
          ]
        }
      ]
    }
  ]
}